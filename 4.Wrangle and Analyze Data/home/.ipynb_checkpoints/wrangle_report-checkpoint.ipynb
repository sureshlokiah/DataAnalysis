{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report - WeRateDogs  Twitter data\n",
    ".\n",
    ".\n",
    "## Author : Suresh Lokiah\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope:\n",
    "\n",
    "This document summarizes steps followed to Gather, Assess, Clean the to make visualizations for WeRateDogs Twitter data. The goal of this exercise is to perform 8 Quality and 2 Tidyness cleanups. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is gathered from 3 data sources \n",
    "\n",
    "1. twitter-archive-enhanced - contains tweet data for 5000+ tweets. It has 'text'field of the tweet and dog \"stage\" fields  (i.e. doggo, floofer, pupper, and puppo). This is a comma delimited file \n",
    "\n",
    "2. Image Predcitions - Each image from the Tweet is processed using neural network to classify the dog breed using 3 predcitions (p1, p2, p3). This file a tab separated file\n",
    "\n",
    "3. Tweet_json - downloaded the data that was gathered using Twitter API. This data has the retweet_count and favorite_count. The response data has JSON format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data\n",
    "\n",
    "Each dataset was systematically reviewed and, observations, quality and tidyness issues were documented at each step. Additionally, the step also makes guidance to \"Next Step\".  So here is the format \n",
    "\n",
    "- Observation\n",
    "    - This section captures the observations made\n",
    "\n",
    "- Quality\n",
    "    - This captures the quality issues noted\n",
    "    \n",
    "- Tidyness\n",
    "    - This captures the Tidyness issues\n",
    "    \n",
    "- Next Step\n",
    "    - Guides to the next steps being performed\n",
    "\n",
    "    \n",
    "The following Quality and Tidyness issues were observed after assessing the datasets\n",
    "\n",
    "#### Issues\n",
    "\n",
    "##### Quality\n",
    "`twitter-archive-enhanced.csv`\n",
    "1. **Incorrect datatype** -\n",
    "    1. **Number fields to Strings** - The following fields have a number datatype - tweet_id, in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id. These must all be String as there is no numerical calculations needed on those.\n",
    "    2. **Object field must be datetime** - The timestamp, retweeted_status_timestamp must be datetime type\n",
    "1. Column `tweet_id` must be a string\n",
    "1. Column `in_reply_to_status_id` must be a string\n",
    "1. Column `in_reply_to_user_id` must be a string\n",
    "1. Fix column name Floofer as Floof\n",
    "1. Fix values in column Floofer to floof\n",
    "1. Create a column as dogtype and fill the value by parsing it from `text` field \n",
    "1. Fix Non-name Dog names from `text` field.\n",
    "1. Fix 'None' name from the text field\n",
    "1. 84% of rows have unknown dog type\n",
    "1. Replace string(None) to literal None\n",
    "\n",
    "`image-predictions.tsv`\n",
    "\n",
    "1. `tweet_id` must be string\n",
    "1. Fix Dog type \n",
    "\n",
    "`tweet-json.txt`\n",
    "\n",
    "1. Fix `id` column and type \n",
    "\n",
    "##### Tidyness\n",
    "\n",
    "1. **Combine Table** - Looks like we can join the dataframes (df_twitter, df_image_predictions, df_ tweet_json ) using tweet_id \n",
    "1. Drop individual dog stage columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "A cloned copy of each dataframe was made with suffix \"_clean\" and was used to clean the data. \n",
    "\n",
    "The following types of cleaning was performed on the data -\n",
    "\n",
    "`twitter-archive-enhanced`\n",
    "1. Fixing the data types\n",
    "2. Replace string value 'None' to  None\n",
    "3. Fixing the Column Name - floofer\n",
    "4. Fixing the Values in Column - floof\n",
    "5. Fixing the dog names\n",
    "6. Fixing Dog Stage\n",
    "7. Drop rows - retweet_status_id isnot null (nan)\n",
    "\n",
    "`image_predictions`\n",
    "8. Fix Columns - tweet_id\n",
    "9. Fix dog breed \n",
    "\n",
    "`tweet_json`\n",
    "\n",
    "10. Fix column name - id\n",
    "11. Fix column type - tweet_id\n",
    "\n",
    "And,\n",
    "\n",
    "12. Combining the dataframes \n",
    "13. Drop individual dog stage columns\n",
    "\n",
    "The resulting clean data was archived into  'twitter_archive_master.csv' file for visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This exercise helped explore the aspects of Wrangling data (Gathere, Assess, Clean and Visualize the data). The Assess and Clean are  iterative process and met the scope of cleaning 8 Quality and 2 Tidiness issues. It provided a good learning opportunity that will come in handy in a realworld dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
